{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6360d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import Dataset\n",
    "from feature_extractor import *\n",
    "from monitors import *\n",
    "from evaluation import Evaluator\n",
    "import torch\n",
    "from models import resnet\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0079ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stat\n",
    "\n",
    "import scipy.stats as ss\n",
    "import statsmodels.api as sa\n",
    "import scikit_posthocs as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e603131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/njemmat/anaconda3/envs/neural-network-monitoring-benchmark/lib/python3.10/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755853668/work/c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "device_name = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf72087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_id_datasets = [\"cifar10\", \"svhn\", \"cifar100\"]\n",
    "\n",
    "all_ood_datasets = [[\"cifar100\", \"svhn\", \"lsun\"],\n",
    "                    [\"cifar10\", \"tiny_imagenet\", \"lsun\"],\n",
    "                    [\"cifar10\", \"svhn\", \"lsun\"]]\n",
    "\n",
    "all_perturbations = [\"brightness\", \"blur\", \"pixelization\"]\n",
    "\n",
    "all_attacks = [\"fgsm\", \"deepfool\", \"pgd\"]\n",
    "\n",
    "\n",
    "react_clip = [0.8, 0.9, 0.95, 0.99]\n",
    "monitor_temperature = [1, 50, 75, 100]\n",
    "\n",
    "\n",
    "all_models = [\"resnet\", \"densenet\"]\n",
    "\n",
    "all_layers_ids = [[32], [98]]\n",
    "\n",
    "cv = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52b4185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aupr_results = {\n",
    "    '1': [], \n",
    "    '50': [],\n",
    "    '75': [],\n",
    "    '100': [],\n",
    "}\n",
    "\n",
    "auroc_results = {\n",
    "    '1': [], \n",
    "    '50': [],\n",
    "    '75': [],\n",
    "    '100': [],\n",
    "}\n",
    "\n",
    "tnr95_results = {\n",
    "    '1': [], \n",
    "    '50': [],\n",
    "    '75': [],\n",
    "    '100': [],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef8400d",
   "metadata": {},
   "source": [
    "def display_result_posthoc_nemenyi_friedman(data, alpha=0.05, display=False):\n",
    "\n",
    "    # Step 1: Perform the Friedman test\n",
    "    friedman_stat, p_value = ss.friedmanchisquare(*data)\n",
    "    print(\"Friedman chi-squared statistic:\", friedman_stat)\n",
    "    print(\"p-value:\", p_value)\n",
    "    \n",
    "    # Step 2: Perform the post hoc Nemenyi test\n",
    "    if p_value < alpha:  # Adjust the significance level as needed\n",
    "        nemenyi_results = sp.posthoc_nemenyi_friedman(data.T)\n",
    "        \n",
    "        if display == True:\n",
    "            # Compare mean of each group with every other group\n",
    "            for i in range(len(nemenyi_results)):\n",
    "                for j in range(i + 1, len(nemenyi_results)):\n",
    "                    group1 = f\"Case {i}\"\n",
    "                    group2 = f\"Case {j}\"\n",
    "                    if nemenyi_results.iloc[i, j] < alpha:  # Adjust the significance level as needed\n",
    "                        if np.mean(data[:, i]) > np.mean(data[:, j]):\n",
    "                            print(f\"...{group1} is significantly greater than {group2}.\")\n",
    "                        else:\n",
    "                            print(f\"...{group1} is significantly less than {group2}.\")\n",
    "                    else:\n",
    "                        print(f\"...There is no significant difference between {group1} and {group2}.\")\n",
    "        return nemenyi_results\n",
    "    else: \n",
    "        print('No significant differences between groups!')\n",
    "        return None #no significance, p-value bigger than alpha\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "770f1c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./Data/train_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./Data/train_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/train_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/train_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/train_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/train_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/train_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/train_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/train_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./Data/train_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./Data/train_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/train_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/train_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/train_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/train_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/train_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/train_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/train_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./Data/test_32x32.mat\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "for h in range(len(all_models)):\n",
    "    model = all_models[h]\n",
    "    for layer in all_layers_ids[h]:\n",
    "        for n in range(len(all_id_datasets)):\n",
    "            id_dataset = all_id_datasets[n]\n",
    "            for i in range(len(all_ood_datasets[n])):\n",
    "                ood_dataset = all_ood_datasets[n][i]\n",
    "\n",
    "                dataset_train = Dataset(id_dataset, \"train\", model, batch_size=batch_size)\n",
    "                dataset_test = Dataset(id_dataset, \"test\", model, batch_size=batch_size)\n",
    "                dataset_ood = Dataset(ood_dataset, \"test\", model, None, None, batch_size=batch_size)\n",
    "\n",
    "                feature_extractor = FeatureExtractor(model, id_dataset, [layer], device_name)\n",
    "                features_train, logits_train, softmax_train, pred_train, lab_train = feature_extractor.get_features(dataset_train)\n",
    "                features_test, logits_test, softmax_test, pred_test, lab_test = feature_extractor.get_features(dataset_test)\n",
    "                features_ood, logits_ood, softmax_ood, pred_ood, lab_ood = feature_extractor.get_features(dataset_ood)\n",
    "\n",
    "                eval_oms = Evaluator(\"oms\", is_novelty=(id_dataset != ood_dataset))\n",
    "                eval_oms.fit_ground_truth(lab_test, lab_ood, pred_test, pred_ood)\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                for temp in monitor_temperature:\n",
    "\n",
    "                    # Moniteur EnergyMonitor\n",
    "                    monitor_energy = EnergyMonitor(temperature=temp)\n",
    "                    monitor_energy.fit()\n",
    "\n",
    "                    scores_test_energy = monitor_energy.predict(logits_test)\n",
    "                    scores_ood_energy = monitor_energy.predict(logits_ood)\n",
    "\n",
    "                    aupr_energy = eval_oms.get_average_precision(scores_test_energy, scores_ood_energy)\n",
    "                    auroc_energy = eval_oms.get_auroc(scores_test_energy, scores_ood_energy)\n",
    "                    tnr95tpr_energy = eval_oms.get_tnr_frac_tpr_oms(scores_test_energy, scores_ood_energy, frac=0.95)\n",
    "\n",
    "                    \n",
    "                    # Stocker les résultats dans le dictionnaire\n",
    "                    aupr_results[str(temp)] += [aupr_energy]\n",
    "                    auroc_results[str(temp)] += [auroc_energy]\n",
    "                    tnr95_results[str(temp)] += [tnr95tpr_energy]\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                \n",
    "            \n",
    "            for k in range(len(all_attacks)):\n",
    "                ood_dataset = id_dataset\n",
    "\n",
    "                adversarial_attack = all_attacks[k]\n",
    "                \n",
    "\n",
    "                dataset_train = Dataset(id_dataset, \"train\", model, batch_size=batch_size)\n",
    "                dataset_test = Dataset(id_dataset, \"test\", model, batch_size=batch_size)\n",
    "                dataset_ood = Dataset(id_dataset, \"test\", model, None, adversarial_attack, batch_size=batch_size)\n",
    "\n",
    "                feature_extractor = FeatureExtractor(model, id_dataset, [layer], device_name)\n",
    "\n",
    "                features_train, logits_train, softmax_train, \\\n",
    "                    pred_train, lab_train = feature_extractor.get_features(dataset_train)\n",
    "                features_test, logits_test, softmax_test, \\\n",
    "                    pred_test, lab_test = feature_extractor.get_features(dataset_test)\n",
    "                features_ood, logits_ood, softmax_ood, \\\n",
    "                    pred_ood, lab_ood = feature_extractor.get_features(dataset_ood)\n",
    "\n",
    "                eval_oms = Evaluator(\"oms\", is_novelty=(id_dataset != ood_dataset))\n",
    "                eval_oms.fit_ground_truth(lab_test, lab_ood, pred_test, pred_ood)\n",
    "                    \n",
    "                    \n",
    "                for temp in monitor_temperature:\n",
    "\n",
    "                    # Moniteur EnergyMonitor\n",
    "                    monitor_energy = EnergyMonitor(temperature=temp)\n",
    "                    monitor_energy.fit()\n",
    "\n",
    "                    scores_test_energy = monitor_energy.predict(logits_test)\n",
    "                    scores_ood_energy = monitor_energy.predict(logits_ood)\n",
    "\n",
    "                    aupr_energy = eval_oms.get_average_precision(scores_test_energy, scores_ood_energy)\n",
    "                    auroc_energy = eval_oms.get_auroc(scores_test_energy, scores_ood_energy)\n",
    "                    tnr95tpr_energy = eval_oms.get_tnr_frac_tpr_oms(scores_test_energy, scores_ood_energy, frac=0.95)\n",
    "\n",
    "                    # Stocker les résultats dans le dictionnaire\n",
    "                    aupr_results[str(temp)] += [aupr_energy]\n",
    "                    auroc_results[str(temp)] += [auroc_energy]\n",
    "                    tnr95_results[str(temp)] += [tnr95tpr_energy]\n",
    "                   \n",
    "                    \n",
    "            for j in range(len(all_perturbations)):\n",
    "                ood_dataset = id_dataset\n",
    "\n",
    "                additional_transform = all_perturbations[j]\n",
    "\n",
    "\n",
    "                dataset_train = Dataset(id_dataset, \"train\", model, batch_size=batch_size)\n",
    "                dataset_test = Dataset(id_dataset, \"test\", model, batch_size=batch_size)\n",
    "                dataset_ood = Dataset(id_dataset, \"test\", model, additional_transform, None, batch_size=batch_size)\n",
    "\n",
    "                feature_extractor = FeatureExtractor(model, id_dataset, [layer], device_name)\n",
    "\n",
    "                features_train, logits_train, softmax_train, \\\n",
    "                    pred_train, lab_train = feature_extractor.get_features(dataset_train)\n",
    "                features_test, logits_test, softmax_test, \\\n",
    "                    pred_test, lab_test = feature_extractor.get_features(dataset_test)\n",
    "                features_ood, logits_ood, softmax_ood, \\\n",
    "                    pred_ood, lab_ood = feature_extractor.get_features(dataset_ood)\n",
    "\n",
    "                eval_oms = Evaluator(\"oms\", is_novelty=(id_dataset != ood_dataset))\n",
    "                eval_oms.fit_ground_truth(lab_test, lab_ood, pred_test, pred_ood)\n",
    "                \n",
    "                \n",
    "                for temp in monitor_temperature:\n",
    "                    # Moniteur EnergyMonitor\n",
    "                    monitor_energy = EnergyMonitor(temperature=temp)\n",
    "                    monitor_energy.fit()\n",
    "\n",
    "                    scores_test_energy = monitor_energy.predict(logits_test)\n",
    "                    scores_ood_energy = monitor_energy.predict(logits_ood)\n",
    "\n",
    "                    aupr_energy = eval_oms.get_average_precision(scores_test_energy, scores_ood_energy)\n",
    "                    auroc_energy = eval_oms.get_auroc(scores_test_energy, scores_ood_energy)\n",
    "                    tnr95tpr_energy = eval_oms.get_tnr_frac_tpr_oms(scores_test_energy, scores_ood_energy, frac=0.95)\n",
    "\n",
    "                     # Stocker les résultats dans le dictionnaire\n",
    "                    aupr_results[str(temp)] += [aupr_energy]\n",
    "                    auroc_results[str(temp)] += [auroc_energy]\n",
    "                    tnr95_results[str(temp)] += [tnr95tpr_energy]\n",
    "                   \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "905e4e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': [0.5075264225472402,\n",
       "  0.7568058076225046,\n",
       "  0.7418597202946514,\n",
       "  0.571151401619054,\n",
       "  0.5341085271317829,\n",
       "  0.1566638489715413,\n",
       "  0.5519811954331766,\n",
       "  0.7227814202604119,\n",
       "  0.529920640594838,\n",
       "  0.3437562080336922,\n",
       "  0.44697842584131275,\n",
       "  0.22925026818705552,\n",
       "  0.5828327199335154,\n",
       "  0.4447199402539208,\n",
       "  0.0007901907356948623,\n",
       "  0.6446351721439749,\n",
       "  0.21427981840693355,\n",
       "  0.21181952132531556,\n",
       "  0.41575185090630584,\n",
       "  0.49463875414858305,\n",
       "  0.44357926984937457,\n",
       "  0.5368400696190292,\n",
       "  0.463291649858814,\n",
       "  0.0003592384145610916,\n",
       "  0.5539807856939027,\n",
       "  0.3261132623426912,\n",
       "  0.47796104743267165,\n",
       "  0.6589977938859124,\n",
       "  0.6979724761004307,\n",
       "  0.9356024792520222,\n",
       "  0.6419744563341387,\n",
       "  0.5400083787180561,\n",
       "  0.015307150050352436,\n",
       "  0.4406638427886952,\n",
       "  0.3320776040685628,\n",
       "  0.531305770374777,\n",
       "  0.3206983140021523,\n",
       "  0.48961696360955,\n",
       "  0.43066682609908724,\n",
       "  0.45734692429581625,\n",
       "  0.36629760739122796,\n",
       "  0.0,\n",
       "  0.11836826235390863,\n",
       "  0.21461890878800505,\n",
       "  0.1558758270533912,\n",
       "  0.29923998454205847,\n",
       "  0.6797629782300657,\n",
       "  0.4552363776890378,\n",
       "  0.4997484150145919,\n",
       "  0.38330441881824673,\n",
       "  0.17276499434175785,\n",
       "  0.4992930721066451,\n",
       "  0.5962241169305724,\n",
       "  0.4786626024004572],\n",
       " '50': [0.404611935518309,\n",
       "  0.6198355930393936,\n",
       "  0.6565602647592612,\n",
       "  0.4724693918512076,\n",
       "  0.44899224806201554,\n",
       "  0.1439842209072978,\n",
       "  0.47192746809939556,\n",
       "  0.5732754640317665,\n",
       "  0.4006577536283692,\n",
       "  0.16782549962255155,\n",
       "  0.2505860383805475,\n",
       "  0.12149866899757633,\n",
       "  0.373548616882346,\n",
       "  0.28035847647498136,\n",
       "  0.0007901907356948623,\n",
       "  0.4396273474178404,\n",
       "  0.15150639702847712,\n",
       "  0.14459798494683607,\n",
       "  0.17449578759254536,\n",
       "  0.17692111309675773,\n",
       "  0.24546847076844525,\n",
       "  0.2143685940823825,\n",
       "  0.17507059298104077,\n",
       "  0.0,\n",
       "  0.21820603062874533,\n",
       "  0.08482575024201355,\n",
       "  0.19904948280682133,\n",
       "  0.4762054837693035,\n",
       "  0.5196974472108415,\n",
       "  0.8934762054837693,\n",
       "  0.47172937521574043,\n",
       "  0.4089512637899735,\n",
       "  0.01299093655589123,\n",
       "  0.32844941323519206,\n",
       "  0.20314560180825014,\n",
       "  0.31603212373587153,\n",
       "  0.1226433895332616,\n",
       "  0.1976962015225796,\n",
       "  0.20156243772171067,\n",
       "  0.23541375966700562,\n",
       "  0.16833622053174668,\n",
       "  0.0,\n",
       "  0.0037877843953251222,\n",
       "  0.09897959183673466,\n",
       "  0.07413996441921367,\n",
       "  0.11863970114646405,\n",
       "  0.45935849542702567,\n",
       "  0.30439263171454334,\n",
       "  0.2969709167756869,\n",
       "  0.2068578426370038,\n",
       "  0.14497673833773417,\n",
       "  0.2997374267824682,\n",
       "  0.18684531059683318,\n",
       "  0.272432844351305],\n",
       " '75': [0.4019429913526209,\n",
       "  0.61396391587488,\n",
       "  0.6533575317604357,\n",
       "  0.4707299123569947,\n",
       "  0.4444961240310078,\n",
       "  0.14304498919883535,\n",
       "  0.4685023505708529,\n",
       "  0.5663496167697848,\n",
       "  0.3935797526274397,\n",
       "  0.1619849815248917,\n",
       "  0.24287814374826178,\n",
       "  0.11780364734395488,\n",
       "  0.3637421346313665,\n",
       "  0.27378640776699026,\n",
       "  0.0007901907356948623,\n",
       "  0.43617957746478875,\n",
       "  0.1443871234007429,\n",
       "  0.1435227589502608,\n",
       "  0.16836864947664032,\n",
       "  0.17194281337758488,\n",
       "  0.2404901710492724,\n",
       "  0.20856700831560626,\n",
       "  0.17083501411859625,\n",
       "  0.0,\n",
       "  0.21183296870541235,\n",
       "  0.0821636011616651,\n",
       "  0.19392414500046595,\n",
       "  0.4668557621598908,\n",
       "  0.5116083622229226,\n",
       "  0.889169030360332,\n",
       "  0.46392820158784953,\n",
       "  0.4042731462086301,\n",
       "  0.01299093655589123,\n",
       "  0.32275536421081874,\n",
       "  0.19608212469391595,\n",
       "  0.3027215942891136,\n",
       "  0.11702339670772055,\n",
       "  0.19080074933237678,\n",
       "  0.19446769500577943,\n",
       "  0.22633209564127432,\n",
       "  0.163766915216791,\n",
       "  0.0,\n",
       "  0.0034887487851678056,\n",
       "  0.09702207413577679,\n",
       "  0.0716213244847782,\n",
       "  0.1179956202499034,\n",
       "  0.4536905835372923,\n",
       "  0.2971789256730646,\n",
       "  0.29334809298581066,\n",
       "  0.20491886927237468,\n",
       "  0.14221048660882685,\n",
       "  0.29781862250050495,\n",
       "  0.17965895249695496,\n",
       "  0.2690988759763765],\n",
       " '100': [0.4006618981530906,\n",
       "  0.6120422760755845,\n",
       "  0.6499412832283549,\n",
       "  0.4685221114604937,\n",
       "  0.44178294573643406,\n",
       "  0.14276321968629657,\n",
       "  0.46843519140362655,\n",
       "  0.5609012835903593,\n",
       "  0.39250732823335954,\n",
       "  0.15713774881799036,\n",
       "  0.23914339067900992,\n",
       "  0.11685009336882668,\n",
       "  0.35994301317820254,\n",
       "  0.2687079910380882,\n",
       "  0.0007901907356948623,\n",
       "  0.42806142410015646,\n",
       "  0.1427362773421379,\n",
       "  0.1433833778025566,\n",
       "  0.16428389073270355,\n",
       "  0.16428389073270355,\n",
       "  0.2397242787847843,\n",
       "  0.20653645329723458,\n",
       "  0.1678096006454215,\n",
       "  0.0,\n",
       "  0.20679159136307423,\n",
       "  0.07938044530493704,\n",
       "  0.18926474699468832,\n",
       "  0.4621283748292888,\n",
       "  0.5050950730118711,\n",
       "  0.8867528101691354,\n",
       "  0.46054539178460474,\n",
       "  0.39763999441418796,\n",
       "  0.01299093655589123,\n",
       "  0.3204638566766197,\n",
       "  0.19363345262761344,\n",
       "  0.29729327781082693,\n",
       "  0.11419347124237711,\n",
       "  0.18729323607955672,\n",
       "  0.19187691817131014,\n",
       "  0.2249603859707211,\n",
       "  0.16193417187617687,\n",
       "  0.0,\n",
       "  0.0032893917117297056,\n",
       "  0.09571012078300711,\n",
       "  0.0715813460731205,\n",
       "  0.11529048048434887,\n",
       "  0.45175834084761046,\n",
       "  0.29653484477650394,\n",
       "  0.2951595048807487,\n",
       "  0.20297989590774568,\n",
       "  0.1414560543191249,\n",
       "  0.29731367400525144,\n",
       "  0.1762484774665043,\n",
       "  0.2660506763192989]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aupr_results\n",
    "auroc_results\n",
    "tnr95_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "262e0e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _plotting import _bron_kerbosch, _find_maximal_cliques, sign_plot, sign_table, sign_array\n",
    "import matplotlib.pyplot as plt\n",
    "import scikit_posthocs as sp\n",
    "from _plotting import *\n",
    "\n",
    "\n",
    "def critical_difference_diagram(\n",
    "        ranks: Union[dict, Series],\n",
    "        sig_matrix: DataFrame,\n",
    "        *,\n",
    "        ax: SubplotBase = None,\n",
    "        label_fmt_left: str = '{label} ({rank:.3g})',\n",
    "        label_fmt_right: str = '({rank:.3g}) {label}',\n",
    "        label_props: dict = None,\n",
    "        marker_props: dict = None,\n",
    "        elbow_props: dict = None,\n",
    "        crossbar_props: dict = None,\n",
    "        text_h_margin: float = 0.01) -> Dict[str, list]:\n",
    "    \n",
    "    \"\"\"Plot a Critical Difference diagram from ranks and post-hoc results.\n",
    "\n",
    "    The diagram arranges the average ranks of multiple groups on the x axis\n",
    "    in order to facilitate performance comparisons between them. The groups\n",
    "    that could not be statistically deemed as different are linked by a\n",
    "    horizontal crossbar [1], [2].\n",
    "\n",
    "    ::\n",
    "\n",
    "                      rank markers\n",
    "         X axis ---------O----O-------------------O-O------------O---------\n",
    "                         |----|                   | |            |\n",
    "                         |    |                   |---crossbar---|\n",
    "                clf1 ----|    |                   | |            |---- clf3\n",
    "                clf2 ---------|                   | |----------------- clf4\n",
    "                                                  |------------------- clf5\n",
    "                    |__|\n",
    "                text_h_margin\n",
    "\n",
    "    In the drawing above, the two crossbars indicate that clf1 and clf2 cannot\n",
    "    be statistically differentiated, the same occurring between clf3, clf4 and\n",
    "    clf5. However, clf1 and clf2 are each significantly lower ranked than clf3,\n",
    "    clf4 and clf5.\n",
    "\n",
    "    \"\"\"\n",
    "    elbow_props = elbow_props or {}\n",
    "    marker_props = {\"zorder\": 3, **(marker_props or {})}\n",
    "    label_props = {\"va\": \"center\", **(label_props or {})}\n",
    "    crossbar_props = {\"color\": \"k\", \"zorder\": 3,\n",
    "                      \"linewidth\": 5, **(crossbar_props or {})}########### MODIFIED BY USER\n",
    "\n",
    "    ax = ax or pyplot.gca()\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.spines['top'].set_position('zero')\n",
    "\n",
    "    # lists of artists to be returned\n",
    "    markers = []\n",
    "    elbows = []\n",
    "    labels = []\n",
    "    crossbars = []\n",
    "\n",
    "    # True if pairwise comparison is NOT significant\n",
    "    adj_matrix = DataFrame(\n",
    "        1 - sign_array(sig_matrix),\n",
    "        index=sig_matrix.index,\n",
    "        columns=sig_matrix.columns,\n",
    "        dtype=bool,\n",
    "    )\n",
    "    \n",
    "    ranks = Series(ranks)  # Standardize if ranks is dict\n",
    "    points_left, points_right = np.array_split(ranks.sort_values(), 2)\n",
    "    \n",
    "    # Sets of points under the same crossbar\n",
    "    crossbar_sets = _find_maximal_cliques(adj_matrix)\n",
    "\n",
    "    # Sort by lowest rank and filter single-valued sets\n",
    "    crossbar_sets = sorted(\n",
    "        (x for x in crossbar_sets if len(x) > 1),\n",
    "        key=lambda x: ranks[list(x)].min()\n",
    "    )\n",
    "\n",
    "    # Create stacking of crossbars: for each level, try to fit the crossbar,\n",
    "    # so that it does not intersect with any other in the level. If it does not\n",
    "    # fit in any level, create a new level for it.\n",
    "    crossbar_levels: list[list[set]] = []\n",
    "    for bar in crossbar_sets:\n",
    "        for level, bars_in_level in enumerate(crossbar_levels):\n",
    "            if not any(bool(bar & bar_in_lvl) for bar_in_lvl in bars_in_level):\n",
    "                ypos = -level-1\n",
    "                bars_in_level.append(bar)\n",
    "                break\n",
    "        else:\n",
    "            ypos = -len(crossbar_levels) - 1\n",
    "            crossbar_levels.append([bar])\n",
    "\n",
    "        crossbars.append(ax.plot(\n",
    "            # Adding a separate line between each pair enables showing a\n",
    "            # marker over each elbow with crossbar_props={'marker': 'o'}.\n",
    "            [ranks[i] for i in bar],\n",
    "            [ypos] * len(bar),\n",
    "            **crossbar_props,\n",
    "        ))\n",
    "\n",
    "    lowest_crossbar_ypos = -len(crossbar_levels)\n",
    "    \n",
    "    custom_color = ['red', 'orange', 'green', 'blue'] ########### ADDED BY USER\n",
    "    label_to_color = dict(zip(list(ranks.index), custom_color)) ########### ADDED BY USER\n",
    "    \n",
    "    def plot_items(points, xpos, label_fmt, label_props):\n",
    "        \"\"\"Plot each marker + elbow + label.\"\"\"\n",
    "        ypos = lowest_crossbar_ypos - 0.5 ########### MODIFIED BY USER\n",
    "        for i, (label, rank) in enumerate(points.items()):\n",
    "            curr_color = label_to_color[label] ########### ADDED BY USER\n",
    "\n",
    "            elbow, *_ = ax.plot(\n",
    "                [xpos, rank, rank],\n",
    "                [ypos, ypos, 0],\n",
    "                **{\"color\": curr_color, **elbow_props},########### ADDED BY USER\n",
    "            )\n",
    "            elbows.append(elbow)\n",
    "            markers.append(\n",
    "                ax.scatter(rank, 0, **{\"color\": curr_color, **marker_props})########### ADDED BY USER\n",
    "            )\n",
    "            labels.append(\n",
    "                ax.text(\n",
    "                    xpos,\n",
    "                    ypos,\n",
    "                    label_fmt.format(label=label, rank=rank),\n",
    "                    **{\"color\": curr_color, **label_props},########### ADDED BY USER\n",
    "                )\n",
    "            )\n",
    "            ypos -= 1\n",
    "\n",
    "    plot_items(\n",
    "        points_left,\n",
    "        xpos=points_left.iloc[0] - text_h_margin,\n",
    "        label_fmt=label_fmt_left,\n",
    "        label_props={\"ha\": \"right\", **label_props},\n",
    "    )\n",
    "    plot_items(\n",
    "        points_right[::-1],\n",
    "        xpos=points_right.iloc[-1] + text_h_margin,\n",
    "        label_fmt=label_fmt_right,\n",
    "        label_props={\"ha\": \"left\", **label_props},\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"markers\": markers,\n",
    "        \"elbows\": elbows,\n",
    "        \"labels\": labels,\n",
    "        \"crossbars\": crossbars,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2341b02f",
   "metadata": {},
   "source": [
    "alpha = 0.05  \n",
    "\n",
    "# AUROC\n",
    "print(\"Post-hoc Nemenyi test for AUROC:\")\n",
    "nemenyi_auroc = display_result_posthoc_nemenyi_friedman(np.array(list(auroc_results.values())), alpha=alpha, display=True)\n",
    "\n",
    "# AUPR\n",
    "print(\"\\nPost-hoc Nemenyi test for AUPR:\")\n",
    "nemenyi_aupr = display_result_posthoc_nemenyi_friedman(np.array(list(aupr_results.values())), alpha=alpha, display=True)\n",
    "\n",
    "# TNR95\n",
    "print(\"\\nPost-hoc Nemenyi test for TNR95:\")\n",
    "nemenyi_tnr95 = display_result_posthoc_nemenyi_friedman(np.array(list(tnr95_results.values())), alpha=alpha, display=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85512429",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'markers': [<matplotlib.collections.PathCollection at 0x7fce8a52ad10>,\n",
       "  <matplotlib.collections.PathCollection at 0x7fcdc9fb6380>,\n",
       "  <matplotlib.collections.PathCollection at 0x7fcdcf002740>,\n",
       "  <matplotlib.collections.PathCollection at 0x7fcdcf0000a0>],\n",
       " 'elbows': [<matplotlib.lines.Line2D at 0x7fcdd5f65a80>,\n",
       "  <matplotlib.lines.Line2D at 0x7fcdc9fb58a0>,\n",
       "  <matplotlib.lines.Line2D at 0x7fcdcf001de0>,\n",
       "  <matplotlib.lines.Line2D at 0x7fcdcf0008e0>],\n",
       " 'labels': [Text(0.2677777777777778, -1.5, '100 (0.278)'),\n",
       "  Text(0.2677777777777778, -2.5, '75 (0.528)'),\n",
       "  Text(0.9266666666666666, -1.5, '(0.917) 1'),\n",
       "  Text(0.9266666666666666, -2.5, '(0.778) 50')],\n",
       " 'crossbars': [[<matplotlib.lines.Line2D at 0x7fcdd5f67310>]]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Post-hoc Nemenyi test for AUPR:\n",
    "\n",
    "dict_data_aupr = aupr_results \n",
    "data_df_aupr = (\n",
    "  pd.DataFrame(dict_data_aupr)\n",
    "  .rename_axis('cv_fold')\n",
    "  .melt(\n",
    "      var_name='estimator',\n",
    "      value_name='score',\n",
    "      ignore_index=False,\n",
    "  )\n",
    "  .reset_index()\n",
    ")\n",
    "avg_rank_aupr = data_df_aupr.groupby('cv_fold').score.rank(pct=True).groupby(data_df_aupr.estimator).mean()\n",
    "ss.friedmanchisquare(*dict_data_aupr.values())\n",
    "test_results_aupr = sp.posthoc_nemenyi_friedman(\n",
    "     data_df_aupr,\n",
    "     melted=True,\n",
    "     block_col='cv_fold',\n",
    "     group_col='estimator',\n",
    "     y_col='score',\n",
    " )\n",
    "test_results_aupr\n",
    "critical_difference_diagram(avg_rank_aupr, test_results_aupr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea679309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'markers': [<matplotlib.collections.PathCollection at 0x7fcdced28be0>,\n",
       "  <matplotlib.collections.PathCollection at 0x7fcdceb48d30>,\n",
       "  <matplotlib.collections.PathCollection at 0x7fcdceb49840>,\n",
       "  <matplotlib.collections.PathCollection at 0x7fcdceb4a200>],\n",
       " 'elbows': [<matplotlib.lines.Line2D at 0x7fcdceb482e0>,\n",
       "  <matplotlib.lines.Line2D at 0x7fcdceb48a60>,\n",
       "  <matplotlib.lines.Line2D at 0x7fcdceb49570>,\n",
       "  <matplotlib.lines.Line2D at 0x7fcdceb49f30>],\n",
       " 'labels': [Text(0.24462962962962964, -0.5, '100 (0.255)'),\n",
       "  Text(0.24462962962962964, -1.5, '75 (0.505)'),\n",
       "  Text(0.9961111111111112, -0.5, '(0.986) 1'),\n",
       "  Text(0.9961111111111112, -1.5, '(0.755) 50')],\n",
       " 'crossbars': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Post-hoc Nemenyi test for AUROC:\n",
    "    \n",
    "dict_data_auroc = auroc_results \n",
    "data_df_auroc = (\n",
    "  pd.DataFrame(dict_data_auroc)\n",
    "  .rename_axis('cv_fold')\n",
    "  .melt(\n",
    "      var_name='estimator',\n",
    "      value_name='score',\n",
    "      ignore_index=False,\n",
    "  )\n",
    "  .reset_index()\n",
    ")\n",
    "avg_rank_auroc = data_df_auroc.groupby('cv_fold').score.rank(pct=True).groupby(data_df_auroc.estimator).mean()\n",
    "ss.friedmanchisquare(*dict_data_auroc.values())\n",
    "test_results_auroc = sp.posthoc_nemenyi_friedman(\n",
    "     data_df_auroc,\n",
    "     melted=True,\n",
    "     block_col='cv_fold',\n",
    "     group_col='estimator',\n",
    "     y_col='score',\n",
    " )\n",
    "test_results_auroc\n",
    "critical_difference_diagram(avg_rank_auroc, test_results_auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6588cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'markers': [<matplotlib.collections.PathCollection at 0x7fcdcec22e30>,\n",
       "  <matplotlib.collections.PathCollection at 0x7fcdcebd3d60>,\n",
       "  <matplotlib.collections.PathCollection at 0x7fcdce8648b0>,\n",
       "  <matplotlib.collections.PathCollection at 0x7fcdce865270>],\n",
       " 'elbows': [<matplotlib.lines.Line2D at 0x7fcdcebd3310>,\n",
       "  <matplotlib.lines.Line2D at 0x7fcdcebd3a90>,\n",
       "  <matplotlib.lines.Line2D at 0x7fcdce8645e0>,\n",
       "  <matplotlib.lines.Line2D at 0x7fcdce864fa0>],\n",
       " 'labels': [Text(0.2677777777777778, -0.5, '100 (0.278)'),\n",
       "  Text(0.2677777777777778, -1.5, '75 (0.5)'),\n",
       "  Text(0.9961111111111112, -0.5, '(0.986) 1'),\n",
       "  Text(0.9961111111111112, -1.5, '(0.736) 50')],\n",
       " 'crossbars': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Post-hoc Nemenyi test for TNR95-TPR:\n",
    "\n",
    "dict_data_tnr95 = tnr95_results \n",
    "data_df_tnr95 = (\n",
    "  pd.DataFrame(dict_data_tnr95)\n",
    "  .rename_axis('cv_fold')\n",
    "  .melt(\n",
    "      var_name='estimator',\n",
    "      value_name='score',\n",
    "      ignore_index=False,\n",
    "  )\n",
    "  .reset_index()\n",
    ")\n",
    "avg_rank_tnr95  = data_df_tnr95.groupby('cv_fold').score.rank(pct=True).groupby(data_df_tnr95.estimator).mean()\n",
    "ss.friedmanchisquare(*dict_data_tnr95.values())\n",
    "test_results_tnr95 = sp.posthoc_nemenyi_friedman(\n",
    "     data_df_tnr95,\n",
    "     melted=True,\n",
    "     block_col='cv_fold',\n",
    "     group_col='estimator',\n",
    "     y_col='score',\n",
    " )\n",
    "test_results_tnr95 \n",
    "critical_difference_diagram(avg_rank_tnr95, test_results_tnr95 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d2d81a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
